{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "-6hmel6sKNSP"
   },
   "outputs": [],
   "source": [
    "def reproduceResult():\n",
    "  seed_value= 0\n",
    "\n",
    "  \n",
    "  with tf.device(\"/gpu:0\"):\n",
    "    ...\n",
    "\n",
    "\n",
    "  os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "  np.random.seed(0)\n",
    "  rn.seed(0)\n",
    "\n",
    "\n",
    "  session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, \n",
    "                                          inter_op_parallelism_threads=1)\n",
    "\n",
    "\n",
    "  tf.compat.v1.set_random_seed(seed_value)\n",
    "  sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
    "  tf.compat.v1.keras.backend.set_session(sess)\n",
    "  tf.compat.v1.keras.backend.clear_session()\n",
    "\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "vURLkAC5_Jp0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\moshi\\AppData\\Local\\Temp\\ipykernel_2116\\1320675762.py:20: The name tf.keras.backend.set_session is deprecated. Please use tf.compat.v1.keras.backend.set_session instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\moshi\\AppData\\Local\\Temp\\ipykernel_2116\\2832172220.py:43: DeprecationWarning: `import kerastuner` is deprecated, please use `import keras_tuner`.\n",
      "  from kerastuner.tuners import RandomSearch\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "  %tensorflow_version 2.x\n",
    "except Exception:\n",
    "  pass\n",
    "  \n",
    "import os \n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random as rn\n",
    "from tensorflow import keras\n",
    "\n",
    "reproduceResult()\n",
    "# %tensorflow_version 2.x\n",
    "# import tensorflow as tf\n",
    "# tf.test.gpu_device_name()\n",
    "# from scipy import integrate\n",
    "# import os\n",
    "# import numpy as np\n",
    "# from tensorflow import keras\n",
    "import tempfile\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "# import tensorflow as tf\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "\n",
    "from tensorflow.keras import callbacks\n",
    "\n",
    "from keras_lr_finder import LRFinder\n",
    "from clr.clr_callback import CyclicLR\n",
    "\n",
    "import tensorflow_model_optimization as tfmot\n",
    "\n",
    "import tqdm\n",
    "\n",
    "import keras_tuner\n",
    "from kerastuner.tuners import RandomSearch\n",
    "from kerastuner.engine.hyperparameters import HyperParameters\n",
    "from attention import Attention\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import PorterStemmer\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from bnlp import SentencepieceTokenizer\n",
    "import gensim\n",
    "import fasttext "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('F:/Context_Aware_Data_Cleaning_Deep/UBMEC/Dataset/ubmec_clean.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of                                                     text   classes\n",
       "0      এই নাটকটি হচ্ছে এই সালের। কিন্তু তখন ইউটিউবে ছ...       joy\n",
       "1       ২০২১ সালে যারা “ কোথাও কেউ নেই ” দেখতে আসে - ...  surprise\n",
       "2       \" বাংলাদেশের ইতিহাসে সর্বশ্রেষ্ঠ নাটক \" \" কোথ...       joy\n",
       "3       এতো সুন্দর নাটক আগে কখনো দেখা হয় নাই,2021 সাল...       joy\n",
       "4       কখনো চিন্তাও করিনি জন্মের ৭-৮ বছর আগের নাটক দ...  surprise\n",
       "...                                                  ...       ...\n",
       "13431   Bravo বললে ছোট করা হবে ৷ সুতরাং হাজারো সালাম ...       joy\n",
       "13432   কি যে করেন না করা স্যার? মৃত্যুকে পরে ভাবছি ব...       joy\n",
       "13433   আপনারা এই সত্যের পথে অবিচল থাকুন দেশবাসী আপনা...       joy\n",
       "13434         এগিয়ে যান। আপনাদের দিকেই তাকিয়ে বাংলাদেশ।        joy\n",
       "13435   দুর্নীতি মুক্ত হলে নিশ্চয় দুর্নীতি মুক্ত হবে ...       joy\n",
       "\n",
       "[13436 rows x 2 columns]>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>classes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13431</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13432</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13433</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13434</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13435</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13436 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        text  classes\n",
       "0      False    False\n",
       "1      False    False\n",
       "2      False    False\n",
       "3      False    False\n",
       "4      False    False\n",
       "...      ...      ...\n",
       "13431  False    False\n",
       "13432  False    False\n",
       "13433  False    False\n",
       "13434  False    False\n",
       "13435  False    False\n",
       "\n",
       "[13436 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>classes</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>anger</th>\n",
       "      <td>2480</td>\n",
       "      <td>2433</td>\n",
       "      <td>বিচার চাই</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>disgust</th>\n",
       "      <td>2079</td>\n",
       "      <td>2042</td>\n",
       "      <td>এর পরে কোনো গাড়ি খেয়ে দিলেই সব সরকারের দোষ পর...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fear</th>\n",
       "      <td>1361</td>\n",
       "      <td>1349</td>\n",
       "      <td>এই দ্রবনে করোনার ভাইরাস মরে কিনা সেটা জানার জ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>joy</th>\n",
       "      <td>3467</td>\n",
       "      <td>3287</td>\n",
       "      <td>ধন্যবাদ</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sadness</th>\n",
       "      <td>2683</td>\n",
       "      <td>2625</td>\n",
       "      <td>অপরাধ অপরাধ এবং অপরাধী কে কারী এবং দুজনেই সমা...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>surprise</th>\n",
       "      <td>1366</td>\n",
       "      <td>1341</td>\n",
       "      <td>কিছুক্ষণ আগে লক্ষ্য করলাম কিছু মানুষ বাঙলাদেশ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          text                                                               \n",
       "         count unique                                                top freq\n",
       "classes                                                                      \n",
       "anger     2480   2433                                         বিচার চাই     5\n",
       "disgust   2079   2042   এর পরে কোনো গাড়ি খেয়ে দিলেই সব সরকারের দোষ পর...    3\n",
       "fear      1361   1349   এই দ্রবনে করোনার ভাইরাস মরে কিনা সেটা জানার জ...    2\n",
       "joy       3467   3287                                           ধন্যবাদ    28\n",
       "sadness   2683   2625   অপরাধ অপরাধ এবং অপরাধী কে কারী এবং দুজনেই সমা...   12\n",
       "surprise  1366   1341   কিছুক্ষণ আগে লক্ষ্য করলাম কিছু মানুষ বাঙলাদেশ...    4"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(\"classes\").describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "joy         3467\n",
       "sadness     2683\n",
       "anger       2480\n",
       "disgust     2079\n",
       "surprise    1366\n",
       "fear        1361\n",
       "Name: classes, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"classes\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DFgD7Seo_Xlq",
    "outputId": "9be2fe5a-b7b5-4488-9cd4-8a48ce6123e8",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique words: 30487\n",
      "[[    0     0     0 ...   233   487   112]\n",
      " [    0     0     0 ...  2063    40   454]\n",
      " [    0     0     0 ...   419    51 13156]\n",
      " ...\n",
      " [    0     0     0 ...    19    85  4573]\n",
      " [    0     0     0 ...    14    22   684]\n",
      " [    0     0     0 ...  2660 30487    41]]\n"
     ]
    }
   ],
   "source": [
    "train, test = train_test_split(df, test_size=0.2, stratify = df[\"classes\"], random_state = 42)\n",
    "num_classes = 6\n",
    "embed_num_dims = 300\n",
    "max_seq_len = 50\n",
    "\n",
    "x_train = train['text']\n",
    "x_test = test['text']\n",
    "\n",
    "y_train = train['classes']\n",
    "y_test = test['classes']\n",
    "\n",
    "texts_train = x_train\n",
    "texts_test = x_test\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(train['text'])\n",
    "\n",
    "sequence_train = tokenizer.texts_to_sequences(texts_train)\n",
    "sequence_test = tokenizer.texts_to_sequences(texts_test)\n",
    "\n",
    "index_of_words = tokenizer.word_index\n",
    "\n",
    "vocab_size = len(index_of_words) + 1\n",
    "\n",
    "print('Number of unique words: {}'.format(len(index_of_words)))\n",
    "\n",
    "X_train_pad = pad_sequences(sequence_train, maxlen = max_seq_len, padding='pre' )\n",
    "X_test_pad = pad_sequences(sequence_test, maxlen = max_seq_len,  padding='pre')\n",
    "\n",
    "print(X_train_pad)\n",
    "\n",
    "\n",
    "encoding = {\n",
    "    \"joy\":0,\n",
    "    \"disgust\":1,\n",
    "    \"sadness\":2,\n",
    "    \"anger\":3,\n",
    "    \"fear\":4,\n",
    "    \"surprise\":5\n",
    "}\n",
    "\n",
    "y_train = [encoding[x] for x in train['classes']]\n",
    "y_test = [encoding[x] for x in test['classes']]\n",
    "\n",
    "\n",
    "\n",
    "y_train = tf.keras.utils.to_categorical(y_train)\n",
    "y_test = tf.keras.utils.to_categorical(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# META EMBADDING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30488, 300)\n"
     ]
    }
   ],
   "source": [
    "def create_embedding_matrix(word_index, embedding_dim):\n",
    "    vocab_size = len(word_index) + 1  # Adding again 1 because of reserved 0 index\n",
    "    embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
    "    with open('F:/Python_code/embedding/glove.840B.300d.txt', encoding=\"utf8\") as f:\n",
    "        for line in f:\n",
    "            word, *vector = line.split()\n",
    "            if word in word_index:\n",
    "                try:\n",
    "                    idx = word_index[word]\n",
    "                    embedding_matrix[idx] = np.array(vector, dtype=np.float32)[:embedding_dim]\n",
    "                except ValueError:\n",
    "                    pass\n",
    "    return embedding_matrix\n",
    "\n",
    "embedd_matrix_glove = create_embedding_matrix(index_of_words, embed_num_dims)\n",
    "print(embedd_matrix_glove.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gGgsd5mMZPKn"
   },
   "source": [
    "# Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3IvOZoK8YGDI",
    "outputId": "fe861031-a89e-45d3-8f7a-42f1e7b6b256"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 30 Complete [00h 00m 35s]\n",
      "val_accuracy: 0.4776785671710968\n",
      "\n",
      "Best val_accuracy So Far: 0.5059523582458496\n",
      "Total elapsed time: 00h 18m 28s\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "Results summary\n",
      "Results in 1708169844\\untitled_project\n",
      "Showing 10 best trials\n",
      "Objective(name=\"val_accuracy\", direction=\"max\")\n",
      "\n",
      "Trial 18 summary\n",
      "Hyperparameters:\n",
      "cnn_1_unit: 96\n",
      "cnn_1_dropout: 0.2\n",
      "lstm_unit: 96\n",
      "lstm_dropout: 0.2\n",
      "Score: 0.5059523582458496\n",
      "\n",
      "Trial 02 summary\n",
      "Hyperparameters:\n",
      "cnn_1_unit: 96\n",
      "cnn_1_dropout: 0.2\n",
      "lstm_unit: 128\n",
      "lstm_dropout: 0.2\n",
      "Score: 0.5033482313156128\n",
      "\n",
      "Trial 08 summary\n",
      "Hyperparameters:\n",
      "cnn_1_unit: 32\n",
      "cnn_1_dropout: 0.1\n",
      "lstm_unit: 96\n",
      "lstm_dropout: 0.4\n",
      "Score: 0.4996279776096344\n",
      "\n",
      "Trial 05 summary\n",
      "Hyperparameters:\n",
      "cnn_1_unit: 32\n",
      "cnn_1_dropout: 0.2\n",
      "lstm_unit: 96\n",
      "lstm_dropout: 0.30000000000000004\n",
      "Score: 0.4992559552192688\n",
      "\n",
      "Trial 14 summary\n",
      "Hyperparameters:\n",
      "cnn_1_unit: 96\n",
      "cnn_1_dropout: 0.2\n",
      "lstm_unit: 96\n",
      "lstm_dropout: 0.5\n",
      "Score: 0.4985119104385376\n",
      "\n",
      "Trial 19 summary\n",
      "Hyperparameters:\n",
      "cnn_1_unit: 80\n",
      "cnn_1_dropout: 0.1\n",
      "lstm_unit: 64\n",
      "lstm_dropout: 0.30000000000000004\n",
      "Score: 0.4985119104385376\n",
      "\n",
      "Trial 23 summary\n",
      "Hyperparameters:\n",
      "cnn_1_unit: 80\n",
      "cnn_1_dropout: 0.1\n",
      "lstm_unit: 192\n",
      "lstm_dropout: 0.4\n",
      "Score: 0.4970238208770752\n",
      "\n",
      "Trial 16 summary\n",
      "Hyperparameters:\n",
      "cnn_1_unit: 64\n",
      "cnn_1_dropout: 0.1\n",
      "lstm_unit: 128\n",
      "lstm_dropout: 0.1\n",
      "Score: 0.495907723903656\n",
      "\n",
      "Trial 13 summary\n",
      "Hyperparameters:\n",
      "cnn_1_unit: 16\n",
      "cnn_1_dropout: 0.2\n",
      "lstm_unit: 224\n",
      "lstm_dropout: 0.2\n",
      "Score: 0.494047611951828\n",
      "\n",
      "Trial 03 summary\n",
      "Hyperparameters:\n",
      "cnn_1_unit: 64\n",
      "cnn_1_dropout: 0.1\n",
      "lstm_unit: 160\n",
      "lstm_dropout: 0.4\n",
      "Score: 0.4929315447807312\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import regularizers\n",
    "import time\n",
    "LOG_DIR = f\"{int(time.time())}\"\n",
    "seed_value= 0\n",
    "\n",
    "\n",
    "\n",
    "def build_model(hp):\n",
    "  \n",
    "  reproduceResult()\n",
    "\n",
    "  print('Ya it comes here')\n",
    "  fake_val = hp.Int(\"cnn_1_unit\",min_value =16, max_value = 96, step = 16)\n",
    "  cnn_1_unit = hp.Int(\"cnn_1_unit\",min_value =16, max_value = 96, step = 16)\n",
    "  cnn_1_dropout = hp.Float(\"cnn_1_dropout\",min_value = 0.1,max_value = 0.3,step = 0.1)\n",
    "\n",
    "  lstm_unit = hp.Int(\"lstm_unit\",min_value =64, max_value = 256, step = 32)\n",
    "  lstm_dropout = hp.Float(\"lstm_dropout\",min_value = 0.1,max_value = 0.5,step = 0.1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  seq_input = keras.layers.Input(shape=(max_seq_len,))\n",
    "\n",
    "  embedded = keras.layers.Embedding(vocab_size,\n",
    "                          embed_num_dims,\n",
    "                          input_length = max_seq_len,\n",
    "                          weights = [embedd_matrix_glove])(seq_input)\n",
    "\n",
    "\n",
    "  lstm = keras.layers.Bidirectional(keras.layers.LSTM(lstm_unit, recurrent_regularizer=regularizers.l2(1e-4),\n",
    "                                                      return_sequences=True,kernel_regularizer=regularizers.l2(1e-4),\n",
    "                                                      bias_regularizer=regularizers.l2(1e-2),\n",
    "                                                      activity_regularizer=regularizers.l2(1e-4),input_shape =(48,)))(embedded)\n",
    "  lstm = keras.layers.Activation(activation='relu')(lstm)\n",
    "  lstm = keras.layers.BatchNormalization()(lstm)\n",
    "  lstm = keras.layers.Dropout(lstm_dropout,seed=seed_value)(lstm)\n",
    "  \n",
    "  \n",
    "  max_pooling = keras.layers.GlobalMaxPooling1D()(lstm)\n",
    "  output = keras.layers.Dense(num_classes, activation='softmax')(max_pooling)\n",
    "\n",
    "  model = keras.Model(inputs = [seq_input], outputs = output)\n",
    "  model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "\n",
    "  return model\n",
    "\n",
    "\n",
    "stop = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy',\n",
    "                              patience=5,\n",
    "                              restore_best_weights=True,\n",
    "                              verbose=0, mode='max')\n",
    "\n",
    "\n",
    "clr_step_size = int((len(X_train_pad)/64))\n",
    "base_lr = 1e-3\n",
    "max_lr = 6e-3\n",
    "mode = 'exp_range'\n",
    "\n",
    "\n",
    "clr = CyclicLR(base_lr = base_lr, max_lr = max_lr, step_size = clr_step_size, mode = mode)\n",
    "\n",
    "\n",
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective = keras_tuner.Objective('val_accuracy', direction=\"max\"),\n",
    "    max_trials = 30,\n",
    "    executions_per_trial = 1,\n",
    "    directory = LOG_DIR\n",
    "    )\n",
    "  \n",
    "tuner.search(x=X_train_pad,y = y_train,epochs = 30, batch_size = 64,callbacks = [stop,clr], \n",
    "             validation_data = (X_test_pad,y_test))\n",
    "\n",
    "\n",
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 4\n",
      "cnn_1_unit (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 16, 'max_value': 96, 'step': 16, 'sampling': 'linear'}\n",
      "cnn_1_dropout (Float)\n",
      "{'default': 0.1, 'conditions': [], 'min_value': 0.1, 'max_value': 0.3, 'step': 0.1, 'sampling': 'linear'}\n",
      "lstm_unit (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 64, 'max_value': 256, 'step': 32, 'sampling': 'linear'}\n",
      "lstm_dropout (Float)\n",
      "{'default': 0.1, 'conditions': [], 'min_value': 0.1, 'max_value': 0.5, 'step': 0.1, 'sampling': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ya it comes here\n"
     ]
    }
   ],
   "source": [
    "#get best hypoerparamter\n",
    "best_hps = tuner.get_best_hyperparameters()[0]\n",
    "model = build_model(best_hps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "168/168 [==============================] - 8s 29ms/step - loss: 2.9307 - accuracy: 0.4265 - val_loss: 2.2672 - val_accuracy: 0.4442\n",
      "Epoch 2/30\n",
      "168/168 [==============================] - 5s 30ms/step - loss: 1.0489 - accuracy: 0.7497 - val_loss: 1.6854 - val_accuracy: 0.4985\n",
      "Epoch 3/30\n",
      "117/168 [===================>..........] - ETA: 1s - loss: 0.3318 - accuracy: 0.9519"
     ]
    }
   ],
   "source": [
    "history = model.fit(x=X_train_pad,y = y_train,epochs = 30, batch_size = 64,callbacks = [stop,clr], \n",
    "             validation_data = (X_test_pad,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PlotGraph(history):\n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    x = range(1, len(acc) + 1)\n",
    "\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(x, acc, 'g', label='Training acc')\n",
    "    plt.plot(x, val_acc, 'b', label='Validation acc')\n",
    "    plt.title('Training and validation accuracy')\n",
    "    plt.legend()\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(x, loss, 'g', label='Training loss')\n",
    "    plt.plot(x, val_loss, 'b', label='Validation loss')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PlotGraph(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = model.predict(X_test_pad)\n",
    "predict_class = np.argmax(predict, axis=1)\n",
    "predict_class = np.array(predict_class)\n",
    "predict_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_lables=np.argmax(y_test, axis=1)\n",
    "predict_lables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(predict_lables, predict_class)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = list(encoding.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cm = pd.DataFrame(cm, index=class_names,columns=class_names)\n",
    "plt.figure(figsize = (10,7))\n",
    "sns.heatmap(df_cm,annot=True, fmt =\"d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(predict_lables, predict_class, target_names =class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "100_percent_test_BiLSTM_best_model_git.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
