{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "-6hmel6sKNSP"
   },
   "outputs": [],
   "source": [
    "def reproduceResult():\n",
    "  seed_value= 0\n",
    "\n",
    "  \n",
    "  with tf.device(\"/gpu:0\"):\n",
    "    ...\n",
    "\n",
    "\n",
    "  os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "  np.random.seed(0)\n",
    "  rn.seed(0)\n",
    "\n",
    "\n",
    "  session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, \n",
    "                                          inter_op_parallelism_threads=1)\n",
    "\n",
    "\n",
    "  tf.compat.v1.set_random_seed(seed_value)\n",
    "  sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
    "  tf.compat.v1.keras.backend.set_session(sess)\n",
    "  tf.compat.v1.keras.backend.clear_session()\n",
    "\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "vURLkAC5_Jp0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\moshi\\AppData\\Local\\Temp\\ipykernel_13272\\1320675762.py:20: The name tf.keras.backend.set_session is deprecated. Please use tf.compat.v1.keras.backend.set_session instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\moshi\\AppData\\Local\\Temp\\ipykernel_13272\\2832172220.py:43: DeprecationWarning: `import kerastuner` is deprecated, please use `import keras_tuner`.\n",
      "  from kerastuner.tuners import RandomSearch\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "  %tensorflow_version 2.x\n",
    "except Exception:\n",
    "  pass\n",
    "  \n",
    "import os \n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random as rn\n",
    "from tensorflow import keras\n",
    "\n",
    "reproduceResult()\n",
    "# %tensorflow_version 2.x\n",
    "# import tensorflow as tf\n",
    "# tf.test.gpu_device_name()\n",
    "# from scipy import integrate\n",
    "# import os\n",
    "# import numpy as np\n",
    "# from tensorflow import keras\n",
    "import tempfile\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "# import tensorflow as tf\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "\n",
    "from tensorflow.keras import callbacks\n",
    "\n",
    "from keras_lr_finder import LRFinder\n",
    "from clr.clr_callback import CyclicLR\n",
    "\n",
    "import tensorflow_model_optimization as tfmot\n",
    "\n",
    "import tqdm\n",
    "\n",
    "import keras_tuner\n",
    "from kerastuner.tuners import RandomSearch\n",
    "from kerastuner.engine.hyperparameters import HyperParameters\n",
    "from attention import Attention\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import PorterStemmer\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from bnlp import SentencepieceTokenizer\n",
    "import gensim\n",
    "import fasttext "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('F:/Context_Aware_Data_Cleaning_Deep/EMONOBA/Dataset/emonoba_train.csv')\n",
    "df_test = pd.read_csv('F:/Context_Aware_Data_Cleaning_Deep/EMONOBA/Dataset/emonoba_val.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of           ID                                               Data  Love  Joy  \\\n",
       "0       5454                            ‡¶≤‡¶ï‡¶æ‡¶≤ ‡¶¨‡¶æ‡¶∏ ‡¶≠‡¶æ‡¶≤‡ßã ‡¶è‡¶ü‡¶æ ‡¶•‡ßá‡¶ï‡ßá      0    0   \n",
       "1      22549  ‡¶ï‡¶§ ‡¶Ö‡¶≠‡¶ø‡¶ú‡¶æ‡¶®‡¶á ‡¶§‡ßã ‡¶ö‡¶≤‡ßá ‡¶ï‡¶ø‡¶®‡ßç‡¶§‡ßÅ ‡¶ì‡ßü‡¶æ‡¶∏‡¶æ‡¶∞ ‡¶™‡¶æ‡¶®‡¶ø‡¶∞ ‡¶Ö‡¶≠‡¶ø‡¶ú‡¶æ‡¶® ‡¶ï...     0    0   \n",
       "2       7033  ‡¶¨‡¶ø‡¶Ø‡¶º‡ßá‡¶∞ ‡¶Æ‡¶π‡¶≤ ‡¶õ‡ßá‡¶°‡¶º‡ßá ‡¶§‡¶ø‡¶®‡¶ø ‡¶¨‡¶ø‡¶∏‡ßç‡¶∞‡¶æ‡¶Æ ‡¶®‡¶ø‡¶§‡ßá ‡¶ö‡¶≤‡ßá ‡¶Ø‡¶æ‡¶® (‡ß¨ ...     0    0   \n",
       "3      21114                  ‡¶ö‡¶æ‡¶ö‡¶æ‡¶ú‡¶ø ‡¶§‡ßã ‡¶ï‡ßá‡¶¨‡¶≤ ‡¶Æ‡¶æ‡¶ï‡ßá ‡¶ß‡¶∞‡ßç‡¶∑‡¶£ ‡¶ï‡¶∞‡ßá‡¶õ‡ßá‡¶®      0    0   \n",
       "4      23683                          ‡¶∏‡¶§‡ßç‡¶Ø‡¶ø‡¶ï‡¶æ‡¶∞ ‡¶Æ‡¶æ‡¶®‡ßÅ‡¶∑ ‡¶§‡¶æ‡¶∞‡¶æ‡¶á ‡¶≠‡¶æ‡¶á      0    1   \n",
       "...      ...                                                ...   ...  ...   \n",
       "18415  25861  ‡¶∏‡¶Æ‡¶∏‡ßç‡¶Ø‡¶æ ‡¶®‡¶æ‡¶á ‡¶á‡¶®‡¶∂‡¶æ‡¶Ü‡¶≤‡ßç‡¶≤‡¶æ‡¶π ‡¶Ü‡¶Æ‡¶∞‡¶æ ‡¶è‡¶ï‡¶¶‡¶ø‡¶® ‡¶ï‡ßç‡¶∞‡¶ø‡¶ï‡ßá‡¶ü ‡¶ï‡ßá ‡¶∂‡¶æ...     0    1   \n",
       "18416  27263  ‡¶ñ‡¶æ‡¶®‡¶ï‡¶ø‡¶∞‡¶™‡ßÅ‡¶≤‡¶æ ‡¶§‡¶∞ ‡¶Æ‡¶æ‡¶ï‡ßá ‡¶ó‡¶ø‡ßü‡ßá ‡¶¨‡¶≤ ‡¶¶‡ßá‡¶π‡ßã ‡¶¶‡¶ø‡¶≤‡¶æ ‡¶Æ‡¶®‡¶ü‡¶æ ‡¶¶‡¶ø‡¶≤‡¶æ...     0    0   \n",
       "18417  13900                                     ‡¶≠‡¶æ‡¶á ‡¶ö‡ßá‡ßü‡¶æ‡¶∞ ‡¶ï‡¶áüôÑ      0    0   \n",
       "18418   1208                         ‡¶∏‡¶¨‡¶ï‡ßü‡¶ü‡¶æ ‡¶§‡ßã ‡¶è‡¶ï‡¶á ‡¶ó‡ßã‡ßü‡¶æ‡¶≤‡ßá‡¶∞ ‡¶ó‡¶æ‡¶á      0    0   \n",
       "18419  18471  ‡¶¨‡¶∏‡¶®‡ßç‡¶§‡ßá‡¶∞ ‡¶´‡ßÅ‡¶≤‡ßá‡¶≤ ‡¶â‡¶™‡¶π‡¶æ‡¶∞ ‡¶§‡ßã ‡¶™‡ßá‡¶≤‡¶æ‡¶Æ ‡¶®‡¶æ' ‡¶∞‡¶ì‡¶∂‡¶®: ‡¶Ü‡¶õ‡ßá ‡¶Ü‡¶õ‡ßá...     0    0   \n",
       "\n",
       "       Surprise  Anger  Sadness  Fear      Topic    Domain  is_admin  \n",
       "0             0      0        1     0     Travel   Youtube     False  \n",
       "1             0      0        1     0   Politics   Youtube     False  \n",
       "2             0      1        0     0   Personal  Facebook     False  \n",
       "3             0      0        1     0  Education  Facebook     False  \n",
       "4             0      0        0     0   Personal   Youtube     False  \n",
       "...         ...    ...      ...   ...        ...       ...       ...  \n",
       "18415         0      0        0     0     Sports   Youtube     False  \n",
       "18416         0      0        1     0      Music   Youtube     False  \n",
       "18417         1      0        0     0  Education   Youtube     False  \n",
       "18418         0      0        1     0  Education   Youtube     False  \n",
       "18419         0      1        0     0  Education  Facebook     False  \n",
       "\n",
       "[18420 rows x 11 columns]>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get the emotion with value 1 or NaN if all values are 0\n",
    "def get_emotion(row):\n",
    "    emotions = ['Love', 'Joy', 'Surprise', 'Anger', 'Sadness', 'Fear']\n",
    "    nonzero_emotions = [emotion for emotion in emotions if row[emotion] == 1]\n",
    "    return nonzero_emotions[0] if nonzero_emotions else np.nan\n",
    "\n",
    "# Create a new column 'Emotion' based on the custom function\n",
    "df_train['Label'] = df_train.apply(get_emotion, axis=1)\n",
    "\n",
    "# Keep only 'Data' and 'Emotion' columns\n",
    "df_train = df_train[['Data', 'Label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column 'Emotion' based on the custom function\n",
    "df_test['Label'] = df_test.apply(get_emotion, axis=1)\n",
    "\n",
    "# Keep only 'Data' and 'Emotion' columns\n",
    "df_test = df_test[['Data', 'Label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18415</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18416</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18417</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18418</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18419</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18420 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Data  Label\n",
       "0      False  False\n",
       "1      False  False\n",
       "2      False  False\n",
       "3      False  False\n",
       "4      False  False\n",
       "...      ...    ...\n",
       "18415  False  False\n",
       "18416  False  False\n",
       "18417  False  False\n",
       "18418  False  False\n",
       "18419  False  False\n",
       "\n",
       "[18420 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">Data</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Anger</th>\n",
       "      <td>3295</td>\n",
       "      <td>3289</td>\n",
       "      <td>‡¶∏‡¶™‡ßç‡¶§‡¶æ‡¶π‡ßá‡¶∞ ‡¶ö‡¶æ‡¶∞ ‡¶¶‡¶ø‡¶®‡¶á ‡¶®‡¶æ‡¶®‡¶æ ‡¶Æ‡¶ø‡¶ü‡¶ø‡¶Ç‡ßü‡ßá ‡¶π‡¶æ‡¶ú‡¶ø‡¶∞‡¶æ ‡¶¶‡¶ø‡¶§‡ßá ‡¶π‡ßü‡•§...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fear</th>\n",
       "      <td>162</td>\n",
       "      <td>162</td>\n",
       "      <td>‡¶Ø‡¶¶‡¶ø ‡¶ó‡¶°‡¶º ‡¶ó‡ßç‡¶∞‡ßá‡¶° ‡¶∏‡¶ø ‡¶ö‡¶≤‡ßá ‡¶Ü‡¶∏‡ßá</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Joy</th>\n",
       "      <td>6478</td>\n",
       "      <td>6450</td>\n",
       "      <td>‡¶Ö‡¶®‡ßá‡¶ï ‡¶≠‡¶æ‡¶≤‡ßã ‡¶≤‡¶æ‡¶ó‡¶≤‡ßã</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Love</th>\n",
       "      <td>3786</td>\n",
       "      <td>3773</td>\n",
       "      <td>‡¶Æ‡¶æ‡¶®‡ßÅ‡¶∑ ‡¶Æ‡¶æ‡¶®‡ßÅ‡¶∑‡ßá‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sadness</th>\n",
       "      <td>3975</td>\n",
       "      <td>3974</td>\n",
       "      <td>‡¶ï‡ßá ‡¶∏‡ßá? ‡¶®‡¶ø‡¶∂‡ßç‡¶ö‡ßü‡¶á ‡¶∂‡ßü‡¶§‡¶æ‡¶® ‡¶ú‡¶æ‡¶Æ‡¶æ‡¶≤! : ‡¶®‡¶æ : ‡¶§‡¶æ ‡¶π‡¶≤‡ßá ‡¶®‡¶ø‡¶∂‡ßç...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Surprise</th>\n",
       "      <td>724</td>\n",
       "      <td>723</td>\n",
       "      <td>‡¶§‡¶æ‡¶ì ‡¶¨‡¶≤‡¶õ‡¶ø‡¶∏ ‡¶≠‡¶æ‡¶≤‡ßã‡¶®‡¶æ !!! ‡¶ï‡¶ø‡¶®‡ßç‡¶§‡ßÅ ‡¶§‡ßã‡¶∞‡ßá ‡¶§‡ßã ‡ß™‡¶ü‡¶æ ‡¶™‡ßç‡¶∞‡¶∂‡ßç‡¶®...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Data                                                               \n",
       "         count unique                                                top freq\n",
       "Label                                                                        \n",
       "Anger     3295   3289  ‡¶∏‡¶™‡ßç‡¶§‡¶æ‡¶π‡ßá‡¶∞ ‡¶ö‡¶æ‡¶∞ ‡¶¶‡¶ø‡¶®‡¶á ‡¶®‡¶æ‡¶®‡¶æ ‡¶Æ‡¶ø‡¶ü‡¶ø‡¶Ç‡ßü‡ßá ‡¶π‡¶æ‡¶ú‡¶ø‡¶∞‡¶æ ‡¶¶‡¶ø‡¶§‡ßá ‡¶π‡ßü‡•§...    2\n",
       "Fear       162    162                          ‡¶Ø‡¶¶‡¶ø ‡¶ó‡¶°‡¶º ‡¶ó‡ßç‡¶∞‡ßá‡¶° ‡¶∏‡¶ø ‡¶ö‡¶≤‡ßá ‡¶Ü‡¶∏‡ßá     1\n",
       "Joy       6478   6450                                   ‡¶Ö‡¶®‡ßá‡¶ï ‡¶≠‡¶æ‡¶≤‡ßã ‡¶≤‡¶æ‡¶ó‡¶≤‡ßã     5\n",
       "Love      3786   3773                                ‡¶Æ‡¶æ‡¶®‡ßÅ‡¶∑ ‡¶Æ‡¶æ‡¶®‡ßÅ‡¶∑‡ßá‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø     2\n",
       "Sadness   3975   3974  ‡¶ï‡ßá ‡¶∏‡ßá? ‡¶®‡¶ø‡¶∂‡ßç‡¶ö‡ßü‡¶á ‡¶∂‡ßü‡¶§‡¶æ‡¶® ‡¶ú‡¶æ‡¶Æ‡¶æ‡¶≤! : ‡¶®‡¶æ : ‡¶§‡¶æ ‡¶π‡¶≤‡ßá ‡¶®‡¶ø‡¶∂‡ßç...    2\n",
       "Surprise   724    723  ‡¶§‡¶æ‡¶ì ‡¶¨‡¶≤‡¶õ‡¶ø‡¶∏ ‡¶≠‡¶æ‡¶≤‡ßã‡¶®‡¶æ !!! ‡¶ï‡¶ø‡¶®‡ßç‡¶§‡ßÅ ‡¶§‡ßã‡¶∞‡ßá ‡¶§‡ßã ‡ß™‡¶ü‡¶æ ‡¶™‡ßç‡¶∞‡¶∂‡ßç‡¶®...    2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.groupby(\"Label\").describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Joy         6478\n",
       "Sadness     3975\n",
       "Love        3786\n",
       "Anger       3295\n",
       "Surprise     724\n",
       "Fear         162\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[\"Label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DFgD7Seo_Xlq",
    "outputId": "9be2fe5a-b7b5-4488-9cd4-8a48ce6123e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique words: 31810\n",
      "[[    0     0     0 ...     4    57    17]\n",
      " [    0     0     0 ...     9     1    54]\n",
      " [    0     0     0 ...     7  5603 11354]\n",
      " ...\n",
      " [    0     0     0 ...     2  2092 31807]\n",
      " [    0     0     0 ...   611 31809  3343]\n",
      " [    0     0     0 ...    40    16    40]]\n"
     ]
    }
   ],
   "source": [
    "# train, test = train_test_split(df, test_size=0.2, stratify = df[\"classes\"], random_state = 42)\n",
    "num_classes = 6\n",
    "embed_num_dims = 300\n",
    "max_seq_len = 50\n",
    "\n",
    "x_train = df_train['Data']\n",
    "x_test = df_test['Data']\n",
    "\n",
    "y_train = df_train['Label']\n",
    "y_test = df_test['Label']\n",
    "\n",
    "texts_train = x_train\n",
    "texts_test = x_test\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(df_train['Data'])\n",
    "\n",
    "sequence_train = tokenizer.texts_to_sequences(texts_train)\n",
    "sequence_test = tokenizer.texts_to_sequences(texts_test)\n",
    "\n",
    "index_of_words = tokenizer.word_index\n",
    "\n",
    "vocab_size = len(index_of_words) + 1\n",
    "\n",
    "print('Number of unique words: {}'.format(len(index_of_words)))\n",
    "\n",
    "X_train_pad = pad_sequences(sequence_train, maxlen = max_seq_len, padding='pre' )\n",
    "X_test_pad = pad_sequences(sequence_test, maxlen = max_seq_len,  padding='pre')\n",
    "\n",
    "print(X_train_pad)\n",
    "\n",
    "encoding = {\n",
    "    \"Love\":0,\n",
    "    \"Joy\":1,\n",
    "    \"Sadness\":2,\n",
    "    \"Anger\":3,\n",
    "    \"Fear\":4,\n",
    "    \"Surprise\":5\n",
    "}\n",
    "\n",
    "y_train = [encoding[x] for x in df_train['Label']]\n",
    "y_test = [encoding[x] for x in df_test['Label']]\n",
    "\n",
    "\n",
    "\n",
    "y_train = tf.keras.utils.to_categorical(y_train)\n",
    "y_test = tf.keras.utils.to_categorical(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# META EMBADDING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31811, 300)\n"
     ]
    }
   ],
   "source": [
    "def create_embedding_matrix(word_index, embedding_dim):\n",
    "    vocab_size = len(word_index) + 1  # Adding again 1 because of reserved 0 index\n",
    "    embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
    "    with open('F:/Python_code/embedding/cc.bn.300.vec',encoding=\"utf8\") as f:\n",
    "        for line in f:\n",
    "            word, *vector = line.split()\n",
    "            if word in word_index:\n",
    "                idx = word_index[word] \n",
    "                embedding_matrix[idx] = np.array(\n",
    "                    vector, dtype=np.float32)[:embedding_dim]\n",
    "    return embedding_matrix\n",
    "\n",
    "\n",
    "embedd_matrix_fasttext = create_embedding_matrix(index_of_words, embed_num_dims)\n",
    "print(embedd_matrix_fasttext.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gGgsd5mMZPKn"
   },
   "source": [
    "# Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3IvOZoK8YGDI",
    "outputId": "fe861031-a89e-45d3-8f7a-42f1e7b6b256"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 Complete [00h 00m 21s]\n",
      "val_accuracy: 0.5876892805099487\n",
      "\n",
      "Best val_accuracy So Far: 0.5876892805099487\n",
      "Total elapsed time: 00h 01m 53s\n",
      "\n",
      "Search: Running Trial #6\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "32                |32                |cnn_1_unit\n",
      "0.2               |0.2               |cnn_1_dropout\n",
      "96                |64                |lstm_unit\n",
      "0.3               |0.1               |lstm_dropout\n",
      "\n",
      "Ya it comes here\n",
      "Epoch 1/30\n",
      "247/288 [========================>.....] - ETA: 0s - loss: 1.4681 - accuracy: 0.4858"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import regularizers\n",
    "import time\n",
    "LOG_DIR = f\"{int(time.time())}\"\n",
    "seed_value= 0\n",
    "\n",
    "\n",
    "\n",
    "def build_model(hp):\n",
    "  \n",
    "  reproduceResult()\n",
    "\n",
    "  print('Ya it comes here')\n",
    "  fake_val = hp.Int(\"cnn_1_unit\",min_value =16, max_value = 96, step = 16)\n",
    "  cnn_1_unit = hp.Int(\"cnn_1_unit\",min_value =16, max_value = 96, step = 16)\n",
    "  cnn_1_dropout = hp.Float(\"cnn_1_dropout\",min_value = 0.1,max_value = 0.3,step = 0.1)\n",
    "\n",
    "  lstm_unit = hp.Int(\"lstm_unit\",min_value =64, max_value = 256, step = 32)\n",
    "  lstm_dropout = hp.Float(\"lstm_dropout\",min_value = 0.1,max_value = 0.5,step = 0.1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  seq_input = keras.layers.Input(shape=(max_seq_len,))\n",
    "\n",
    "  embedded = keras.layers.Embedding(vocab_size,\n",
    "                          embed_num_dims,\n",
    "                          input_length = max_seq_len,\n",
    "                          weights = [embedd_matrix_fasttext])(seq_input)\n",
    "\n",
    "  cnn = keras.layers.Conv1D(cnn_1_unit,3,kernel_regularizer=regularizers.l2(1e-4),\n",
    "                            bias_regularizer=regularizers.l2(1e-2),\n",
    "                            activity_regularizer=regularizers.l2(1e-4))(embedded)\n",
    "  cnn = keras.layers.Activation(activation='relu')(cnn)\n",
    "  cnn = keras.layers.BatchNormalization()(cnn)\n",
    "  cnn = keras.layers.Dropout(cnn_1_dropout,seed=seed_value)(cnn)  \n",
    "  \n",
    "  max_pooling = keras.layers.GlobalMaxPooling1D()(cnn)\n",
    "  output = keras.layers.Dense(num_classes, activation='softmax')(max_pooling)\n",
    "\n",
    "  model = keras.Model(inputs = [seq_input], outputs = output)\n",
    "  model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "\n",
    "  return model\n",
    "\n",
    "\n",
    "stop = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy',\n",
    "                              patience=5,\n",
    "                              restore_best_weights=True,\n",
    "                              verbose=0, mode='max')\n",
    "\n",
    "\n",
    "clr_step_size = int((len(X_train_pad)/64))\n",
    "base_lr = 1e-3\n",
    "max_lr = 6e-3\n",
    "mode = 'exp_range'\n",
    "\n",
    "\n",
    "clr = CyclicLR(base_lr = base_lr, max_lr = max_lr, step_size = clr_step_size, mode = mode)\n",
    "\n",
    "\n",
    "\n",
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective = keras_tuner.Objective('val_accuracy', direction=\"max\"),\n",
    "    max_trials = 30,\n",
    "    executions_per_trial = 1,\n",
    "    directory = LOG_DIR\n",
    "    )\n",
    "  \n",
    "tuner.search(x=X_train_pad,y = y_train,epochs = 30, batch_size = 64,callbacks = [stop,clr], \n",
    "             validation_data = (X_test_pad,y_test))\n",
    "\n",
    "\n",
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get best hypoerparamter\n",
    "best_hps = tuner.get_best_hyperparameters()[0]\n",
    "model = build_model(best_hps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x=X_train_pad,y = y_train,epochs = 30, batch_size = 64,callbacks = [stop,clr], \n",
    "             validation_data = (X_test_pad,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PlotGraph(history):\n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    x = range(1, len(acc) + 1)\n",
    "\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(x, acc, 'g', label='Training acc')\n",
    "    plt.plot(x, val_acc, 'b', label='Validation acc')\n",
    "    plt.title('Training and validation accuracy')\n",
    "    plt.legend()\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(x, loss, 'g', label='Training loss')\n",
    "    plt.plot(x, val_loss, 'b', label='Validation loss')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PlotGraph(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = model.predict(X_test_pad)\n",
    "predict_class = np.argmax(predict, axis=1)\n",
    "predict_class = np.array(predict_class)\n",
    "predict_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_lables=np.argmax(y_test, axis=1)\n",
    "predict_lables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(predict_lables, predict_class)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = list(encoding.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cm = pd.DataFrame(cm, index=class_names,columns=class_names)\n",
    "plt.figure(figsize = (10,7))\n",
    "sns.heatmap(df_cm,annot=True, fmt =\"d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(predict_lables, predict_class, target_names =class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "100_percent_test_BiLSTM_best_model_git.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
